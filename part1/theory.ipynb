{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e862383",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "title: Mathematical Preliminaries\n",
    "math: \n",
    "    '\\abs': '\\left\\lvert #1 \\right\\rvert' \n",
    "    '\\norm': '\\left\\lvert #1 \\right\\rvert' \n",
    "    '\\Set': '\\left\\{ #1 \\right\\}'\n",
    "    '\\mc': '\\mathcal{#1}'\n",
    "    '\\M': '\\boldsymbol{#1}'\n",
    "    '\\R': '\\mathsf{#1}'\n",
    "    '\\RM': '\\boldsymbol{\\mathsf{#1}}'\n",
    "    '\\op': '\\operatorname{#1}'\n",
    "    '\\E': '\\op{E}'\n",
    "    '\\d': '\\mathrm{\\mathstrut d}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78fcea",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "**DIVE into Deep Learning**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06cceb",
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5048de",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The following is a lecture series that introduces the basic theory of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76967d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "::::{card}\n",
    ":header: [open in new tab](https://www.youtube.com/embed/videoseries?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    ":::{iframe} https://www.youtube.com/embed/videoseries?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\n",
    ":width: 100%\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4adc05",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What to know about vector calculus?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7caada",
   "metadata": {},
   "source": [
    "::::{card}\n",
    ":header: [open in new tab](https://www.cs.cityu.edu.hk/~ccha23/dl/Notation.mp4)\n",
    ":::{iframe} https://www.cs.cityu.edu.hk/~ccha23/dl/Notation.mp4\n",
    ":width: 100%\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5c5d4",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Vectors](https://en.wikipedia.org/wiki/Euclidean_vector) are represented in lowercase boldface font as in\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\M{x} &:= \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}= [x_i]\\in \\mathbb{R}^n  \n",
    "&\\text{such as}\\quad \\M{x}&:= \\begin{bmatrix} 1 \\\\ 2 \\\\ \\vdots \\\\ 9 \\end{bmatrix} \\text{, and}  \\tag{column vector}\\\\\n",
    "\\M{x}^\\intercal &=\\begin{bmatrix}x_1 & x_2 & \\cdots & x_n \\end{bmatrix} & \\text{such as}\\quad \\M{x}^\\intercal &= \\begin{bmatrix} 1 & 2 & \\cdots & 9 \\end{bmatrix}.\\tag{row vector}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- The above example defines a Euclidean vector, which is a 1-D array of ($n$) real numbers (from $\\mathbb{R}$) organized into a column or a row.\n",
    "- A column vector can be transposed ($(\\cdot)^\\intercal$) into a row vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seq = np.arange(1, 10)  # 1D array\n",
    "x = seq.reshape(-1, 1)  # column vector\n",
    "x_transposed = x.transpose()  # row vector\n",
    "\n",
    "print(\"Column vector:\", x, \"Row vector:\", x_transposed, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642b96e",
   "metadata": {},
   "source": [
    "[Matrices](https://en.wikipedia.org/wiki/Matrix_(mathematics)) in uppercase boldface font:\n",
    "\n",
    "$$\n",
    "\\begin{align}\\M{W} \n",
    "&:=\\begin{bmatrix}w_{11} & w_{12} & \\cdots & w_{1n}\\\\\n",
    "w_{21} &  \\ddots &  & \\vdots\\\\\n",
    "\\vdots &  & \\ddots & \\vdots \\\\\n",
    "w_{m1} & \\cdots  & \\cdots & w_{mn}\\\\\n",
    "\\end{bmatrix} \n",
    "=[w_{ij}] \\in \\mathbb{R}^{mn}\n",
    "&\\text{such as} \\quad\n",
    " \\M{W} \n",
    "&:= \n",
    "\\begin{bmatrix}1 & 2 & 3 \\\\\n",
    "4 & 5 & 6  \\\\\n",
    "7 & 8 & 9  \\end{bmatrix}, \\text{and}\n",
    "\\\\\n",
    "\\M{W}^\\intercal &=\n",
    "\\begin{bmatrix}w_{11} & w_{21} & \\cdots & w_{m1}\\\\\n",
    "w_{21} &  \\ddots &  & \\vdots\\\\\n",
    "\\vdots &  & \\ddots & \\vdots \\\\\n",
    "w_{1n} & \\cdots  & \\cdots & w_{mn}\\\\\n",
    "\\end{bmatrix}\n",
    "&\\text{such as} \\quad\n",
    " \\M{W} \n",
    "&:= \n",
    "\\begin{bmatrix}1 & 4 & 7 \\\\\n",
    "2 & 5 & 8  \\\\\n",
    "3 & 5 & 9  \\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "- The above defines a Euclidean matrix, which is a 2-D array of real numbers organized into a table with rows and columns.\n",
    "- Transposing a matrix turns its rows (columns) into columns (rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.arange(1, 10).reshape(3, -1)  # 3-by-3 matrix\n",
    "\n",
    "print(\"W:\", W, \"W^T:\", W.transpose(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0cb2e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- [Matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\M{W}\\M{x} = \\begin{bmatrix}w_{11} & w_{12} & \\cdots \\\\\n",
    "w_{21} & \\ddots &  \\\\\n",
    "\\vdots &  &  \\end{bmatrix}\n",
    "\\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}w_{11}x_1 + w_{12}x_2 + \\cdots \\\\ w_{21}x_1+\\cdots \\\\ \\vdots \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccdfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.arange(1, 10).reshape(3, -1)\n",
    "x = np.arange(1, 4).reshape(-1, 1)\n",
    "Wx = W @ x\n",
    "\n",
    "print(\"W:\", W, \"x:\", x, \"Wx:\", Wx, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5adddf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What to know about Probability Theory?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113091f7",
   "metadata": {},
   "source": [
    "::::{card}\n",
    ":header: [open in new tab](https://www.cs.cityu.edu.hk/~ccha23/dl/Distribution.mp4)\n",
    ":::{iframe} https://www.cs.cityu.edu.hk/~ccha23/dl/Distribution.mp4\n",
    ":width: 100%\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b48515",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Joint distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution#Mixed_case):  \n",
    "\n",
    "$$\n",
    "p_{\\RM{x}\\R{y}}(\\M{x},y)\n",
    "= \\underbrace{p_{\\R{y}|\\RM{x}}(y|\\M{x})}_{\n",
    "\\underbrace{\\Pr}_{\n",
    "\\text{probability measure}\\kern-3em}\\Set{\\R{y}=y|\\RM{x}=\\M{x}}} \\cdot \\underbrace{p_{\\RM{x}}(\\M{x})\n",
    "}_{(\\underbrace{\\partial_{x_1}}_{\\text{partial derivative w.r.t. $x_1$}\\kern-5em} \\partial_{x_2}\\cdots)\\Pr\\Set{\\RM{x} \\leq \\M{x}}\\kern-4em}\\kern1em \\text{where}$$    \n",
    "- $p_{\\R{y}|\\RM{x}}(y|\\M{x})$ is the *probability mass function [(pmf)](https://en.wikipedia.org/wiki/Probability_mass_function)* of $\\R{y}=y\\in \\mc{Y}$ [conditioned](https://en.wikipedia.org/wiki/Conditional_probability_distribution) on $\\RM{x}=\\M{x}\\in \\mc{X}$, and\n",
    "- $p_{\\RM{x}}(\\M{x})$ is the *(multivariate) probability density function [(pdf)](https://en.wikipedia.org/wiki/Probability_density_function#Densities_associated_with_multiple_variables)* of $\\RM{x}=\\M{x}\\in \\mc{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7670be",
   "metadata": {},
   "source": [
    "::::{card}\n",
    ":header: [open in new tab](https://www.cs.cityu.edu.hk/~ccha23/dl/Expectation.mp4)\n",
    ":::{iframe} https://www.cs.cityu.edu.hk/~ccha23/dl/Expectation.mp4\n",
    ":width: 100%\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ae4ed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For any function $g$ of $(\\RM{x},y)$, the expectations are:  \n",
    "  \n",
    "$$\n",
    "\\begin{align}\n",
    "E[g(\\RM{x},\\R{y})|\\RM{x}]&=\\sum_{y\\in \\mc{Y}} g(\\RM{x},y)\\cdot p_{\\R{y}|\\RM{x}}(y|\\RM{x})\\tag{conditional exp.}\n",
    "\\\\\n",
    "E[g(\\RM{x},\\R{y})] &=\\int_{\\mc{X}} \\underbrace{\\sum_{y\\in \\mc{Y}} g(\\RM{x},y)\\cdot \\underbrace{p_{\\RM{x},\\R{y}}(\\M{x},y)}_{p_{\\R{y}|\\RM{x}}(y|\\M{x}) p_{\\R{x}}(\\M{x})}\\kern-1.7em}_{E[g(\\RM{x},\\R{y})|\\RM{x}]}\\kern1.4em\\,d \\M{x} \\tag{exp.}\\\\\n",
    "&= E[E[g(\\RM{x},\\R{y})|\\RM{x}]] \\tag{iterated exp.}\n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
