{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Logging with Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "**DIVE into Deep Learning**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:25:03.509658Z",
     "start_time": "2021-05-21T10:25:03.503618Z"
    },
    "init_cell": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logging the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To call additional functions during training, we can add the functions to the `callbacks` parameter of the model `fit` method. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:25:36.213353Z",
     "start_time": "2021-05-21T10:25:03.513872Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import tqdm.keras\n",
    "\n",
    "if input('Train? [Y/n]').lower() != 'n':\n",
    "    model.fit(ds_b[\"train\"],\n",
    "              epochs=6,\n",
    "              validation_data=ds_b[\"test\"],\n",
    "              verbose=0,\n",
    "              callbacks=[tqdm.keras.TqdmCallback(verbose=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The above code uses [`tqdm.keras.TqdmCallback()`](https://tqdm.github.io/docs/keras/) to return a callback function that displays a graphical progress bar:\n",
    "- Setting `verbose=0` for the method `fit` disables the default text-based progress bar.\n",
    "- Setting `verbose=2` for the class `TqdmCallback` show and keep the progress bars for training each batch. Try changing `verbose` to other values to see different effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An important use of callback functions is to save the models and results during training for further analysis. We define the following function `train_model` for this purpose:\n",
    "- Take a look at the docstring to learn its basic usage, and then\n",
    "- learn the implementations in the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:25:36.224305Z",
     "start_time": "2021-05-21T10:25:36.216523Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pytz\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    fit_params={},\n",
    "    log_root=\".\",\n",
    "    save_log_params=None,\n",
    "    save_model_params=None,\n",
    "    debug_params=None,\n",
    "):\n",
    "    \"\"\"Train and test the model, and return the log directory path name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_root: str\n",
    "        Root directory for creating log directory\n",
    "\n",
    "    fit_params: dict\n",
    "        Dictionary of parameters to pass to model.fit.\n",
    "    save_log_params: dict\n",
    "        Dictionary of parameters to pass to\n",
    "        tf.keras.callbacks.TensorBoard to save the results for TensorBoard.\n",
    "        The default value None means no logging of the results.\n",
    "    save_model_params: dict\n",
    "        Dictionary of parameters to pass to\n",
    "        tf.keras.callbacks.ModelCheckpoint to save the model to checkpoint\n",
    "        files.\n",
    "        The default value None means no saving of the models.\n",
    "    debug_params: dict\n",
    "        Dictionary of parameters to pass to\n",
    "        tf.debugging.experimental.enable_dump_debug_info for debugger\n",
    "        v2 in tensorboard.\n",
    "        The default value None means no logging of the debug information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str: log directory path that points to a subfolder of log_root named\n",
    "        using the current time.\n",
    "    \"\"\"\n",
    "    # use a subfolder named by the current time to distinguish repeated runs\n",
    "    log_dir = os.path.join(\n",
    "        log_root,\n",
    "        datetime.datetime.now(tz=pytz.timezone(\"Asia/Hong_Kong\")).strftime(\n",
    "            \"%Y%m%d-%H%M%S\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    callbacks = fit_params.pop(\"callbacks\", []).copy()\n",
    "\n",
    "    if save_log_params is not None:\n",
    "        # add callback to save the training log for further analysis by tensorboard\n",
    "        callbacks.append(tf.keras.callbacks.TensorBoard(log_dir, **save_log_params))\n",
    "\n",
    "    if save_model_params is not None:\n",
    "        # save the model as checkpoint files after each training epoch\n",
    "        callbacks.append(\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                os.path.join(log_dir, \"{epoch}.ckpt\"), **save_model_params\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if debug_params is not None:\n",
    "        # save information for debugger v2 in tensorboard\n",
    "        tf.debugging.experimental.enable_dump_debug_info(log_dir, **debug_params)\n",
    "\n",
    "    # training + testing (validation)\n",
    "    model.fit(\n",
    "        ds_b[\"train\"], validation_data=ds_b[\"test\"], callbacks=callbacks, **fit_params\n",
    "    )\n",
    "\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:26:21.123243Z",
     "start_time": "2021-05-21T10:25:36.226424Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "fit_params = {\"epochs\": 6, \"callbacks\": [tqdm.keras.TqdmCallback()], \"verbose\": 0}\n",
    "log_root = os.path.join(user_home, \"log\")  # log folder\n",
    "save_log_params = {\"update_freq\": 100, \"histogram_freq\": 1}\n",
    "save_model_params = {\"save_weights_only\": True, \"verbose\": 1}\n",
    "debug_params = {\"tensor_debug_mode\": \"FULL_HEALTH\", \"circular_buffer_size\": -1}\n",
    "\n",
    "if input(\"Train? [Y/n]\").lower() != \"n\":\n",
    "    model = compile_model(create_simple_model())\n",
    "    log_dir = train_model(\n",
    "        model,\n",
    "        fit_params=fit_params,\n",
    "        log_root=log_root,\n",
    "        save_log_params=save_log_params,\n",
    "        save_model_params=save_model_params,\n",
    "        debug_params=debug_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By providing the `save_model_params` to the callback [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_checkpoints_during_training), the model is saved at the end of each epoch to `log_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:26:21.308481Z",
     "start_time": "2021-05-21T10:26:21.125083Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "!ls {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Saving the model is useful because it often takes a long time to train a neural network. To reload the model from the latest checkpoint and continue to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:27:15.158246Z",
     "start_time": "2021-05-21T10:26:21.313384Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input(\"Continue to train? [Y/n]\").lower() != \"n\":\n",
    "    # load the weights of the previously trained model\n",
    "    restored_model = compile_model(create_simple_model())\n",
    "    restored_model.load_weights(tf.train.latest_checkpoint(log_dir))\n",
    "    # continue to train\n",
    "    with tf.device(\"CPU\"):  # train with CPU instead\n",
    "        train_model(restored_model, log_root=log_root, save_log_params=save_log_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By providing [`tf.keras.callbacks.TensorBoard`](https://www.tensorflow.org/tensorboard/get_started#using_tensorboard_with_keras_modelfit) as a callback function to the `fit` method earlier, the training logs can be analyzed using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:27:31.919846Z",
     "start_time": "2021-05-21T10:27:15.162166Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input('Execute? [Y/n]').lower() != 'n':\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `SCALARS` tab shows the curves of training and validation losses/accuracies after different batches/epoches. The curves often have jitters as the gradient descent is stochastic (random). To see the typical performance, a smoothing factor $\\theta\\in [0,1]$ can be applied on the left panel. The smoothed curve $\\bar{l}(t)$ of the original curve $l(t)$ is defined as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\bar{l}(t) = \\theta \\bar{l}(t-1) + (1-\\theta) l(t)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is called the moving average. Try changing the smoothing factor on the left panel to see the effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{admonition} Exercise\n",
    "If the smoothing factor $\\theta$ is too large, would it cause bias when using empirical loss or performance to estimate the actual loss or performance? If so, is estimate overly optimistic or pessimistic?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T17:01:10.111999Z",
     "start_time": "2021-02-25T17:01:10.105064Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4591d3e2623444d89ade756d7a66fda2",
     "grade": true,
     "grade_id": "smoothing",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also visualize the input images in TensorBoard:\n",
    "- Run the following cell to write the images to the log directory.\n",
    "- Click the `refresh` button on the top of the previous TensorBoard panel.\n",
    "- Click the `IMAGE` tab to show the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:28:00.994076Z",
     "start_time": "2021-05-21T10:27:31.924120Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input(\"Execute? [Y/n]\").lower() != \"n\":\n",
    "    file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        # Don't forget to reshape.\n",
    "        images = np.reshape(\n",
    "            [image for (image, label) in ds[\"train\"].take(25)], (-1, 28, 28, 1)\n",
    "        )\n",
    "        tf.summary.image(\"25 training data examples\", images, max_outputs=25, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In addition to presenting the results, TensorBoard is useful for debugging deep learning. In particular, learn\n",
    "- to check the model graph under the [`GRAPHS`](https://www.tensorflow.org/tensorboard/graphs) tab, \n",
    "- to debug using the [`DEBUGGER v2` tab](https://www.tensorflow.org/tensorboard/debugger_v2), and\n",
    "- to [publish your results](https://www.tensorflow.org/tensorboard/get_started#tensorboarddev_host_and_share_your_ml_experiment_results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TensorBoard can also show simultaneously the logs of different runs stored in different subfolders of the log directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:28:09.476208Z",
     "start_time": "2021-05-21T10:28:00.997167Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input('Execute? [Y/n]').lower() != 'n':\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir {log_root}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can select different runs on the left panel to compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that loading the log to TensorBoard may consume a lot of memory. You can list the TensorBoard notebook instances and kill those you do not need anymore by running `!kill {pid}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:28:09.488366Z",
     "start_time": "2021-05-21T10:28:09.479971Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "\n",
    "tb.notebook.list()  # list all the running TensorBoard notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "while (pid := input('pid to kill? (press enter to exit)')):\n",
    "    !kill {pid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8306b333f3414e4d33b7180a4bbc87d5",
     "grade": false,
     "grade_id": "check-dropout",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "```{admonition} Exercise\n",
    "Train the following network with [dropout](https://en.wikipedia.org/wiki/Dilution_(neural_networks)#Dropout). Try to tune the network for the best accuracy. Put your training code inside the body of the conditional `if input...`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:29:35.125298Z",
     "start_time": "2021-05-21T10:28:09.498004Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0db79f676e1ea1afb3fffccb1bb83feb",
     "grade": false,
     "grade_id": "dropout",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def create_dropout_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Dense(128, activation=tf.keras.activations.relu),\n",
    "            tf.keras.layers.Dropout(0.2),  # dropout\n",
    "            tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax),\n",
    "        ],\n",
    "        name=\"Dropout\",\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = compile_model(create_dropout_model())\n",
    "print(model.summary())\n",
    "\n",
    "if input(\"Train? [Y/n]\").lower() != \"n\":\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29f5c02e6b8ede1d3ee700c5ab264add",
     "grade": false,
     "grade_id": "check-cnn",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{admonition} Exercise\n",
    "Explore the [convolutional neural network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network). Try to tune the network for the best accuracy.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:41:54.039696Z",
     "start_time": "2021-05-21T10:29:35.126906Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "340ff2649de706f48db72869e365a402",
     "grade": false,
     "grade_id": "cnn",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ],\n",
    "        name=\"CNN\",\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = compile_model(create_cnn_model())\n",
    "print(model.summary())\n",
    "\n",
    "if input(\"Train? [Y/n]\").lower() != \"n\":\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4bac2d9f2a87655c0e7b343007c5efa7",
     "grade": false,
     "grade_id": "check-tb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{admonition} Exercise\n",
    "Launch TensorBoard to show the best performances of each of the two neural network architectures. Note that to clean up the log of the inferior results, you may need to kill the TensorBoard instance. It is easier to use the vscode interface or the terminal in the lab interface to remove folders.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:49:02.631369Z",
     "start_time": "2021-05-21T10:41:54.042591Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40fb5cf2c2f466d33eaf53b3ac1888e9",
     "grade": false,
     "grade_id": "tb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input('Execute? [Y/n]').lower() != 'n':\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run out of storage, you should remove some of the log files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T10:49:54.539729Z",
     "start_time": "2021-05-21T10:49:02.633974Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input('Remove all logs? [Y/n]').lower() != 'n':\n",
    "    !rm -rf {log_root}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Remember to release the resources if it is no longer used. You can release the memory or GPU memory by `Kernel->Shut Down Kernel`.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
