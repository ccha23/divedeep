{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533dc6b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "title: Logging with Tensorboard\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2333e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "**DIVE into Deep Learning**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d29cc",
   "metadata": {
    "editable": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d977f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logging the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c8c52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To call additional functions during training, we can add the functions to the `callbacks` parameter of the model `fit` method. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58febd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "if input(\"Train? [Y/n]\").lower() != \"n\":\n",
    "    model.fit(\n",
    "        ds_b[\"train\"],\n",
    "        epochs=6,\n",
    "        validation_data=ds_b[\"test\"],\n",
    "        verbose=0,\n",
    "        callbacks=[TqdmCallback(verbose=2)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7165d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The above code uses [TqdmCallback()`](https://tqdm.github.io/docs/keras/) to return a callback function that displays a graphical progress bar:\n",
    "- Setting `verbose=0` for the method `fit` disables the default text-based progress bar.\n",
    "- Setting `verbose=2` for the class `TqdmCallback` show and keep the progress bars for training each batch. Try changing `verbose` to other values to see different effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4108416",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An important use of callback functions is to save the models and results during training for further analysis. We define the following function `train_model` for this purpose:\n",
    "- Take a look at the docstring to learn its basic usage, and then\n",
    "- learn the implementations in the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44019a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pytz\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    fit_params={},\n",
    "    log_root=\".\",\n",
    "    save_log_params=None,\n",
    "    save_model_params=None\n",
    "):\n",
    "    \"\"\"Train and test the model, and return the log directory path name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_root: str\n",
    "        Root directory for creating log directory\n",
    "\n",
    "    fit_params: dict\n",
    "        Dictionary of parameters to pass to model.fit.\n",
    "    save_log_params: dict\n",
    "        Dictionary of parameters to pass to\n",
    "        tf.keras.callbacks.TensorBoard to save the results for TensorBoard.\n",
    "        The default value None means no logging of the results.\n",
    "    save_model_params: dict\n",
    "        Dictionary of parameters to pass to\n",
    "        tf.keras.callbacks.ModelCheckpoint to save the model to checkpoint\n",
    "        files.\n",
    "        The default value None means no saving of the models.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str: log directory path that points to a subfolder of log_root named\n",
    "        using the current time.\n",
    "    \"\"\"\n",
    "    # use a subfolder named by the current time to distinguish repeated runs\n",
    "    log_dir = os.path.join(\n",
    "        log_root,\n",
    "        datetime.datetime.now(tz=pytz.timezone(\"Asia/Hong_Kong\")).strftime(\n",
    "            \"%Y%m%d-%H%M%S\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    callbacks = fit_params.pop(\"callbacks\", []).copy()\n",
    "\n",
    "    if save_log_params is not None:\n",
    "        # add callback to save the training log for further analysis by tensorboard\n",
    "        callbacks.append(tf.keras.callbacks.TensorBoard(log_dir, **save_log_params))\n",
    "\n",
    "    if save_model_params is not None:\n",
    "        # save the model as checkpoint files after each training epoch\n",
    "        callbacks.append(\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                os.path.join(log_dir, \"{epoch}.ckpt\"), **save_model_params\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # training + testing (validation)\n",
    "    model.fit(\n",
    "        ds_b[\"train\"], validation_data=ds_b[\"test\"], callbacks=callbacks, **fit_params\n",
    "    )\n",
    "\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11fcc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3d2a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "fit_params = {\"epochs\": 6, \"callbacks\": [TqdmCallback()], \"verbose\": 0}\n",
    "log_root = os.path.join(user_home, \"log\")  # log folder\n",
    "save_log_params = {\"update_freq\": 100, \"histogram_freq\": 1}\n",
    "save_model_params = {\"save_weights_only\": True, \"verbose\": 1}\n",
    "\n",
    "if input(\"Train? [Y/n]\").lower() != \"n\":\n",
    "    model = compile_model(create_simple_model())\n",
    "    log_dir = train_model(\n",
    "        model,\n",
    "        fit_params=fit_params,\n",
    "        log_root=log_root,\n",
    "        save_log_params=save_log_params,\n",
    "        save_model_params=save_model_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa83643",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By providing the `save_model_params` to the callback [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_checkpoints_during_training), the model is saved at the end of each epoch to `log_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151a170",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "!ls {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25135035",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Saving the model is useful because it often takes a long time to train a neural network. To reload the model from the latest checkpoint and continue to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a733e0a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input(\"Continue to train? [Y/n]\").lower() != \"n\":\n",
    "    # load the weights of the previously trained model\n",
    "    restored_model = compile_model(create_simple_model())\n",
    "    restored_model.load_weights(tf.train.latest_checkpoint(log_dir))\n",
    "    # continue to train\n",
    "    train_model(restored_model, log_root=log_root, save_log_params=save_log_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c3ca6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By providing [`tf.keras.callbacks.TensorBoard`](https://www.tensorflow.org/tensorboard/get_started#using_tensorboard_with_keras_modelfit) as a callback function to the `fit` method earlier, the training logs can be analyzed using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5069b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input('Execute? [Y/n]').lower() != 'n':\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir {log_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744461d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "\n",
    "tb.notebook.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9611b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `SCALARS` tab shows the curves of training and validation losses/accuracies after different batches/epoches. The curves often have jitters as the gradient descent is stochastic (random). To see the typical performance, a smoothing factor $\\theta\\in [0,1]$ can be applied on the left panel. The smoothed curve $\\bar{l}(t)$ of the original curve $l(t)$ is defined as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\bar{l}(t) = \\theta \\bar{l}(t-1) + (1-\\theta) l(t)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is called the moving average. Try changing the smoothing factor on the left panel to see the effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034ab93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:1\n",
    "If the smoothing factor $\\theta$ is too large, would it cause bias when using empirical loss or performance to estimate the actual loss or performance? If so, is estimate overly optimistic or pessimistic?\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e238ae4",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4591d3e2623444d89ade756d7a66fda2",
     "grade": true,
     "grade_id": "smoothing",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1430d3",
   "metadata": {},
   "source": [
    "We can also visualize the input images in TensorBoard:\n",
    "- Run the following cell to write the images to the log directory.\n",
    "- Click the `refresh` button on the top of the previous TensorBoard panel.\n",
    "- Click the `IMAGE` tab to show the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd37b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input(\"Execute? [Y/n]\").lower() != \"n\":\n",
    "    file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        # Don't forget to reshape.\n",
    "        images = np.reshape(\n",
    "            [image for (image, label) in ds[\"train\"].take(25)], (-1, 28, 28, 1)\n",
    "        )\n",
    "        tf.summary.image(\"25 training data examples\", images, max_outputs=25, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92fbd8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In addition to presenting the results, TensorBoard is useful for debugging deep learning. In particular, learn\n",
    "- to check the model graph under the [`GRAPHS`](https://www.tensorflow.org/tensorboard/graphs) tab, \n",
    "- to debug using the [`DEBUGGER v2` tab](https://www.tensorflow.org/tensorboard/debugger_v2), and\n",
    "- to [publish your results](https://www.tensorflow.org/tensorboard/get_started#tensorboarddev_host_and_share_your_ml_experiment_results)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f0c9fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TensorBoard can also show simultaneously the logs of different runs stored in different subfolders of the log directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45557daa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can select different runs on the left panel to compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f60df1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that loading the log to TensorBoard may consume a lot of memory. You can list the TensorBoard notebook instances and kill those you do not need anymore by running `!kill {pid}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af7996",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "while (pid := input('pid to kill? (press enter to exit)')):\n",
    "    !kill {pid}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18030dc",
   "metadata": {},
   "source": [
    "## Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd32c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09088c6c41584b885ddc8971d90775d5",
     "grade": false,
     "grade_id": "check-dropout",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:2\n",
    "Train the following network with [dropout](https://en.wikipedia.org/wiki/Dilution_(neural_networks)#Dropout). Try to tune the network for the best accuracy. Put your training code inside the body of the conditional `if input...`.\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d1b05",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23864c0631a6e926ebd74468c8367dd1",
     "grade": false,
     "grade_id": "dropout",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def create_dropout_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=tf.keras.activations.relu),\n",
    "            tf.keras.layers.Dropout(0.2),  # dropout\n",
    "            tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax),\n",
    "        ],\n",
    "        name=\"Dropout\",\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = compile_model(create_dropout_model())\n",
    "print(model.summary())\n",
    "\n",
    "if input(\"Train? [Y/n]\").lower() != \"n\":\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a59ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24ef4defb0ca382cd816ab8a0b400cdf",
     "grade": false,
     "grade_id": "check-cnn",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:3\n",
    "Explore the [convolutional neural network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network). Try to tune the network for the best accuracy.\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6d286",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f22b8fa7d059a71eaac29f314dd6fb8b",
     "grade": false,
     "grade_id": "cnn",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ],\n",
    "        name=\"CNN\",\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = compile_model(create_cnn_model())\n",
    "print(model.summary())\n",
    "\n",
    "if input(\"Train? [Y/n]\").lower() != \"n\":\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689f33c",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05fcbc",
   "metadata": {},
   "source": [
    "If you run out of storage, you should remove some of the log files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133986f2",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "if input('Remove all logs? [Y/n]').lower() != 'n':\n",
    "    !rm -rf {log_root}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf50f11",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Remember to release the resources if it is no longer used. You can release the memory or GPU memory by `Kernel->Shut Down Kernel`.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
